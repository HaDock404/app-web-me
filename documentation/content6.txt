In the field of computer vision, image segmentation plays a crucial role in many applications, such as medicine, surveillance, and autonomous driving. The use of convolutional neural networks (CNN) has proven to be particularly effective in this task. Among the most efficient architectures, U-Net has emerged as a solution powerful for semantic segmentation.

In this project I focused on training a U-net neural network to carry out image segmentation taken from a dashcam camera.

Dans le domaine de la vision par ordinateur, la segmentation d'images joue un r√¥le crucial dans de nombreuses applications, telles que la m√©decine, la surveillance et la conduite autonome. L'utilisation de r√©seaux de neurones convolutifs (CNN) s'est av√©r√©e particuli√®rement efficace pour cette t√¢che. Parmi les architectures les plus performantes, U-Net s'est impos√©e comme une solution performante pour la segmentation s√©mantique.

Je me suis concentr√© ici sur l'entra√Ænement d'un r√©seau de neurone U-net pour de la segementation d'images captur√© par une cam√©ra embarqu√© dans l'objectif 




La vision par ordinateur permet de segmenter des √©l√©ments dans des images et joue un r√¥le crucial dans de nombreuses applications, comme la m√©decine, la surveillance et la conduite autonome. L'utilisation de r√©seaux de neurones convolutifs (CNN) s'est av√©r√©e particuli√®rement efficace pour cette t√¢che. Parmi les architectures les plus performantes, U-Net s'est impos√©e comme une solution performante pour la segmentation s√©mantique.

Je me suis concentr√© ici sur l'entra√Ænement d'un r√©seau de neurone U-net pour de la segmentation d'images captur√© par une cam√©ra embarqu√© dans l'objectif d'accompagner un syst√®me embarqu√© de conduite autonome.

Les images des cam√©ras embarqu√©es dans les v√©hicules autonomes fournissent un flux continu de donn√©es visuelles, n√©cessitant une analyse rapide et pr√©cise pour permettre le transport du v√©hicule jusqu'√† sa destination. J'ai r√©alis√© un entrainement de mod√®le afin de r√©pondre √† ce flux de donn√©es et de garantir la s√©curit√© du v√©hicule.

L'entra√Ænement du mod√®le √† pu √™tre r√©alis√© gr√¢ce au travail formidable et open source d'annotation du site CityScapes. L'entrainement √† √©t√© r√©alis√© sur 6.000 images de Dashcam ou un masque de couleur √† √©t√© appliqu√© permettant de d√©terminer pour chaque √©l√©ment d'une image le segment auquel il appartient.

Explication compl√®te de U-net

Explication de mon utilisation de la m√©thode LabelEncoder en comparaison avec la m√©thode One-hot Encoding

Explication des m√©triques sur des donn√©es de test (similarit√© avec la cam√©ra de capture et l'environnement allemand identique) pr√©cision de 0.52 voiture, 0.91 route, 0.9 batiment, 0.78 nature, 0.8 ciel

Donner une conclusion sur l'utilisation de U-net et ma m√©thode, et des propositions d'am√©liorations









La vision par ordinateur permet de segmenter des √©l√©ments dans des images et joue un r√¥le crucial dans de nombreuses applications, notamment en m√©decine, en surveillance et dans les v√©hicules autonomes. Gr√¢ce √† l'utilisation de r√©seaux de neurones convolutifs (CNN), nous pouvons identifier et d√©limiter des objets dans des images avec une pr√©cision remarquable.

Parmi les architectures les plus efficaces pour la segmentation s√©mantique, le mod√®le U-Net s‚Äôest impos√© comme un standard gr√¢ce √† sa capacit√© √† capturer √† la fois le contexte global et les d√©tails fins d‚Äôune image.



Dans ce projet, je me suis concentr√© sur l‚Äôentra√Ænement d‚Äôun mod√®le U-Net pour segmenter des images captur√©es par cam√©ra embarqu√©e dans le but d‚Äôassister un syst√®me de conduite autonome.

Les cam√©ras embarqu√©es dans les v√©hicules fournissent un flux continu d‚Äôimages n√©cessitant une analyse rapide et fiable afin de permettre au v√©hicule de prendre des d√©cisions en temps r√©el, tout en garantissant la s√©curit√© des passagers et des autres usagers de la route.

L'entra√Ænement de mon mod√®le a √©t√© rendu possible gr√¢ce au jeu de donn√©es open source Cityscapes, qui fournit des images urbaines annot√©es avec soin. J‚Äôai utilis√© 6 000 images dashcam annot√©es o√π un masque color√© indique, pixel par pixel, le segment auquel chaque √©l√©ment appartient (route, voiture, ciel, v√©g√©tation, b√¢timent, etc.).



U-Net est une architecture de r√©seau de neurones convolutifs con√ßue initialement pour la segmentation d‚Äôimages m√©dicales, mais particuli√®rement adapt√©e aux t√¢ches n√©cessitant une pr√©cision pixel par pixel.

Sa structure en forme de U se compose de deux parties :

Chemin contractant (encoder) : s√©rie de convolutions et de max-pooling qui permettent d‚Äôextraire les caract√©ristiques contextuelles de l‚Äôimage tout en r√©duisant sa taille.

Chemin expansif (decoder) : s√©ries de convolutions et d‚Äôup-sampling permettant de reconstruire l‚Äôimage segment√©e tout en r√©cup√©rant les d√©tails fins.

La particularit√© de U-Net r√©side dans les connexions skip (ponts) reliant les couches de m√™me taille entre l‚Äôencodeur et le d√©codeur, permettant de transf√©rer les d√©tails locaux perdus pendant le downsampling directement dans la phase de reconstruction.

Cette capacit√© √† combiner contexte global et pr√©cision locale est ce qui rend U-Net si performant pour la segmentation d‚Äôimages en conduite autonome.



Pour la segmentation, chaque pixel doit √™tre associ√© √† un label de classe. Deux m√©thodes principales existent :

One-Hot Encoding :

Cr√©e un vecteur de longueur √©gale au nombre de classes pour chaque pixel.

Plus co√ªteux en m√©moire (par exemple, pour une image 1024x512 avec 5 classes, cela donne 1024x512x5).

N√©cessite de travailler avec des canaux multiples et des fonctions de perte adapt√©es comme categorical_crossentropy.

LabelEncoder (avec encodage entier) :

Associe √† chaque pixel un entier repr√©sentant la classe.

Moins gourmand en m√©moire.

Permet l'utilisation de sparse_categorical_crossentropy tout en conservant des performances comparables.

Dans mon cas, j‚Äôai utilis√© LabelEncoder pour encoder les masques de segmentation en entiers afin de simplifier la gestion des donn√©es tout en permettant un entra√Ænement efficace sur GPU, notamment pour traiter le volume √©lev√© d‚Äôimages dashcam tout en conservant de bonnes performances m√©moire.



Pour √©valuer les performances du mod√®le, j‚Äôai test√© U-Net sur un jeu de donn√©es dashcam captur√©es dans des environnements similaires √† ceux du jeu d'entra√Ænement (environnements urbains allemands).

Voici les pr√©cisions par classe obtenues sur les donn√©es de test :

üöó Voiture : 0.52

üõ£Ô∏è Route : 0.91

üè¢ B√¢timent : 0.90

üå≥ Nature : 0.78

‚òÅÔ∏è Ciel : 0.80

Ces r√©sultats montrent que U-Net est particuli√®rement performant sur les surfaces larges et homog√®nes comme les routes et les b√¢timents, mais rencontre plus de difficult√© sur des objets mobiles de petite taille comme les v√©hicules, notamment en raison du faible nombre de pixels les repr√©sentant et des variations de forme.



L‚Äôutilisation de U-Net pour la segmentation d‚Äôimages dashcam s‚Äôest r√©v√©l√©e efficace pour la pr√©paration de donn√©es de perception en conduite autonome. L‚Äôutilisation de LabelEncoder a permis de r√©duire la consommation m√©moire tout en conservant de bonnes performances.





////////////////////////////////////////////////
U-Net est une architecture de r√©seau de neurones convolutifs con√ßue initialement pour la segmentation d‚Äôimages m√©dicales, mais particuli√®rement adapt√©e aux t√¢ches n√©cessitant une pr√©cision pixel par pixel.

Sa structure se compose d'un chemin contractant (Encoder), une s√©rie de convolutions et de max-pooling qui permettent d'extraire les caract√©ristiques contextuelles d'une image tout en r√©duisant sa taille. Et d'un chemin expansif (Decoder), une s√©ries de convolutions et d'up-sampling qui permet de reconstruire l'image segment√©e tout en r√©cup√©rant les d√©tails fins.

La particularit√© de U-Net r√©side dans les connexions skip (ponts) reliant les couches de m√™me taille entre l‚Äôencodeur et le d√©codeur, permettant de transf√©rer les d√©tails locaux perdus pendant le downsampling directement dans la phase de reconstruction.

Cette capacit√© √† combiner contexte global et pr√©cision locale est ce qui rend U-Net si performant pour la segmentation d‚Äôimages en conduite autonome.


//////////////////////////////////////////////
Pour r√©aliser une segmentation efficace, il est essentiel que chaque pixel de l‚Äôimage soit associ√© √† un label de classe (route, v√©hicule, ciel, v√©g√©tation, etc.).

Habituellement, dans ce type de projet, on privil√©gie la m√©thode One-Hot Encoding, qui consiste √† cr√©er, pour chaque pixel, un vecteur de longueur √©gale au nombre de classes. Ainsi, pour une image 1024x512 avec 5 classes, cela g√©n√®re un tenseur de dimension 1024x512x5. Cette m√©thode facilite l‚Äôapprentissage du mod√®le car elle explicite clairement la pr√©sence de chaque classe, pixel par pixel, et permet l‚Äôutilisation de la fonction de perte categorical_crossentropy, adapt√©e aux classifications multi-classes. Cependant, cette approche est co√ªteuse en m√©moire, car elle n√©cessite de g√©rer plusieurs canaux en parall√®le, ce qui peut rapidement devenir limitant lorsque l‚Äôon traite de grands volumes d‚Äôimages haute d√©finition.

Dans mon projet, j'ai choisi d‚Äôutiliser une approche alternative bas√©e sur l'encodage LabelEncoder pour les masques de segmentation. Cette m√©thode attribue √† chaque pixel un entier unique correspondant √† la classe du pixel, ce qui permet de conserver la m√™me taille que l'image d'origine (par exemple 1024x512x1 au lieu de 1024x512x5), tout en repr√©sentant l‚Äôensemble des classes dans un masque unique. Cette repr√©sentation compacte autorise l‚Äôutilisation de la fonction de perte sparse_categorical_crossentropy, qui est √©quivalente √† categorical_crossentropy mais adapt√©e aux labels sous forme d‚Äôentiers.

L‚Äôutilisation de LabelEncoder m‚Äôa permis de simplifier la gestion des donn√©es tout en optimisant l‚Äôutilisation de la m√©moire GPU, rendant possible l'entra√Ænement de mon mod√®le U-Net sur un grand nombre d'images dashcam sans compromis sur les performances. Cette approche est particuli√®rement utile pour les projets de segmentation embarqu√©e en conduite autonome, o√π la m√©moire et la rapidit√© d'inf√©rence sont des contraintes fortes √† respecter tout en maintenant une qualit√© de segmentation satisfaisante.